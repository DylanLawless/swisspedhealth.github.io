I" <h2 id="data-generation">Data generation</h2>
<p>We generate data using the Swiss Multi-Omics Center (SMOC) <a href="http://smoc.ethz.ch/">http://smoc.ethz.ch</a>.
This data is then analysed according to the personal requirements for each patient.
We use the Swiss Multi-Omics Center (SMOC) molecular profiling platform to provide us with robust data, research, and simultaneous insights for clinicians.
This allows use to generate better informed treatment decisions based on molecular insights.</p>

<blockquote>
  <p>‚ÄúEach patient‚Äôs individual molecular makeup and unique characteristics will be the basis for guiding the medical decisions and restoring health.‚Äù
Personalized Health and Related Technologies (PHRT) is a strategic focus area of the ETH Domain; the latter embracing key research institutions like ETHZ, EPFL, PSI, EMPA, Eawag and WSL.
PHRT‚Äôs goals include improving the quality of Personalized Health and Precision Medicine by providing a choice of individual therapeutic strategies for patients.
PHRT aims to support and drive transformation in Personalized Health by providing clinicians with access to ETH technologies in order to evaluate their potential contributions to clinical decision making.
The PHRT research program complements infrastructure efforts undertaken by the Swiss Personalized Health Network (SPHN) and the Swiss Data Science Center (SDSC).
Within the PHRT program, SMOC is an engine for multi-omics data generation, analysis, interpretation.
For secure data processing and sharing, SMOC is integrated into the SPHN/BioMEdIT secure computational infrastructure.
<a href="http://smoc.ethz.ch/#overview">http://smoc.ethz.ch</a></p>
</blockquote>

<ul>
  <li>Clinical Stream: High quality molecular data on the DNA, RNA, Protein, Metabolite and Lipid level for gaining clinical insights.</li>
  <li>Exploratory Research Stream: Integration, visualization and analysis of omics data mapped onto biological networks and pathways.</li>
  <li>SPHN BioMedIT infrastructure integration: For data lineage tracking, secure data management, data sharing, secondary and tertiary analysis.</li>
</ul>

<h3 id="genomics-data">Genomics data</h3>
<p>From the Clinical Genomic Analysis Center (CGAC), 
clinical Grade Sequencing (ISO 15189 accredited):
Whole Genome Sequencing (WGS),
Whole Exome Sequencing (WES),
RNA Sequencing (RNASeq).</p>

<h3 id="proteotyping-data">Proteotyping data</h3>
<p>From the Clinical Proteotype Analysis Center (CPAC),
Quantitative Proteotyping:
Proteotype analysis (DDA, DIA, PRM),
Post-translational modification analysis,
Spatial proteotype analysis.</p>

<h3 id="metabolomics--lipidomics-data">Metabolomics &amp; Lipidomics data</h3>
<p>From the Clinical Metabolomics Analysis Center
(CMAC):
Small molecule analysis,
Targeted metabolomics,
Untargeted metabolomics,
Lipidomics.</p>

<hr class="major" />

<h2 id="data-analysis">Data analysis</h2>

<h3 id="dna-analysis">DNA analysis</h3>
<p>We apply best-practices protocols for consistent analysis of genomic data.</p>

<p>For example, the initial data preperation protocols follows the GATK (Genome Analysis Toolkit) best-practices pipeline.
This is a widely used and highly recommended method for genomic analysis.
The pipeline consists of several steps, including DNA preparation, sequencing, read mapping, variant calling, variant filtering, and functional annotation.</p>

<p>DNA preparation involves the extraction of high-quality DNA from the sample, followed by library preparation and target enrichment.
The DNA is then sequenced using a next-generation sequencing (NGS) platform, producing millions of short reads.
The GATK analysis begins with read mapping, which involves aligning the short reads to a reference genome.
This step is followed by local realignment and base quality score recalibration, which improve the accuracy of the read alignments and base quality scores, respectively.</p>

<p>Variant calling is the next step in the pipeline, which involves identifying differences (variants) between the sample and the reference genome.
The GATK variant calling method is based on a probabilistic model, which takes into account the sequencing error rates and other sources of noise in the data.
After variant calling, variant filtering is performed to remove low-confidence variants and artifacts.
The GATK recommends a set of best-practice filtering criteria, which include quality scores, strand bias, and mapping quality.
Finally, functional annotation is performed to determine the potential impact of the variants on protein function and gene regulation.
This step involves using publicly available databases and tools to annotate the variants with information such as gene function, conservation, and potential pathogenicity.</p>

<p>Overall, the GATK best-practices pipeline provides a robust and comprehensive approach to genomic analysis, allowing researchers to accurately identify and annotate genetic variants that may be relevant to disease susceptibility, drug response, and other important biological processes.</p>

:ET